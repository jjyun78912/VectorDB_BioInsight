"""
ë…¼ë¬¸ ì‹¬ì¸µ í‰ê°€ ì‹œìŠ¤í…œ (Paper Deep Evaluator).

PubMed/DOIì—ì„œ ë…¼ë¬¸ì„ ê°€ì ¸ì™€ Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬
ì¥ì , í•œê³„ì , ê°œì„  ë°©í–¥ì„ í¬í•¨í•œ ì¢…í•©ì ì¸ í‰ê°€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

Usage:
    # DOIë¡œ ë…¼ë¬¸ í‰ê°€
    python scripts/paper_evaluator.py --doi "10.1038/s41586-025-09896-x"

    # PMIDë¡œ ë…¼ë¬¸ í‰ê°€
    python scripts/paper_evaluator.py --pmid "41501451"

    # PubMed ê²€ìƒ‰ í›„ ìµœì‹  ë…¼ë¬¸ í‰ê°€
    python scripts/paper_evaluator.py --search "mitochondrial transfer neuropathy 2026"

    # ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
    python scripts/paper_evaluator.py --doi "10.1038/..." --output evaluation.md

ë¹„ìš© ë¹„êµ (1M tokens ê¸°ì¤€):
    - Claude Opus: $15 input / $75 output
    - Gemini 2.0 Flash: $0.10 input / $0.40 output (150x ì €ë ´!)
"""

import os
import sys
import json
import asyncio
import aiohttp
import argparse
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field, asdict
from typing import Optional, List, Dict, Any
import re

sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.app.core.config import DATA_DIR, setup_logging
from backend.app.core.web_crawler_agent import WebCrawlerAgent, FetchedPaper, FullTextFetcher

logger = setup_logging(__name__)

# Gemini API ì„¤ì •
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models"
DEFAULT_MODEL = "gemini-2.0-flash"  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸


@dataclass
class PaperEvaluation:
    """ë…¼ë¬¸ í‰ê°€ ê²°ê³¼."""
    # ë…¼ë¬¸ ê¸°ë³¸ ì •ë³´
    title: str
    authors: List[str]
    journal: str
    year: int
    doi: str
    pmid: str
    url: str

    # ì—°êµ¬ ê°œìš”
    research_summary: str = ""
    key_findings: List[str] = field(default_factory=list)
    methodology: str = ""

    # í‰ê°€ ê²°ê³¼
    strengths: List[Dict[str, str]] = field(default_factory=list)  # {"title": "", "description": ""}
    limitations: List[Dict[str, str]] = field(default_factory=list)
    future_directions: List[Dict[str, Any]] = field(default_factory=list)  # {"area": "", "suggestion": "", "timeline": "", "impact": ""}

    # ì í•©ì„± í‰ê°€
    relevance_scores: Dict[str, Dict[str, Any]] = field(default_factory=dict)  # {"field": {"score": 5, "reason": ""}}

    # ë©”íƒ€ë°ì´í„°
    citation_count: int = 0
    altmetric_score: float = 0.0
    evaluated_at: str = ""
    model_used: str = ""

    def __post_init__(self):
        if not self.evaluated_at:
            self.evaluated_at = datetime.now().isoformat()

    def to_markdown(self) -> str:
        """í‰ê°€ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜."""
        md = []

        # ë…¼ë¬¸ ì •ë³´
        md.append(f"## ğŸ“„ {self.year}ë…„ ë…¼ë¬¸ ë¶„ì„\n")
        md.append(f"### **ë…¼ë¬¸ ì •ë³´**")
        md.append(f"- **ì œëª©**: {self.title}")
        md.append(f"- **ì €ë„**: {self.journal} ({self.year})")
        md.append(f"- **ì €ì**: {', '.join(self.authors[:5])}{'...' if len(self.authors) > 5 else ''}")
        if self.doi:
            md.append(f"- **DOI**: [{self.doi}](https://doi.org/{self.doi})")
        if self.pmid:
            md.append(f"- **PMID**: [{self.pmid}](https://pubmed.ncbi.nlm.nih.gov/{self.pmid}/)")
        if self.citation_count > 0:
            md.append(f"- **ì¸ìš© ìˆ˜**: {self.citation_count}")
        md.append("")

        # ì—°êµ¬ ê°œìš”
        md.append("---\n")
        md.append("## ğŸ”¬ ì—°êµ¬ ê°œìš”\n")
        md.append(self.research_summary)
        md.append("")

        # ì£¼ìš” ë°œê²¬
        if self.key_findings:
            md.append("### ì£¼ìš” ë°œê²¬")
            for i, finding in enumerate(self.key_findings, 1):
                md.append(f"{i}. {finding}")
            md.append("")

        # ë°©ë²•ë¡ 
        if self.methodology:
            md.append("### ì—°êµ¬ ë°©ë²•ë¡ ")
            md.append(self.methodology)
            md.append("")

        # ì¥ì 
        md.append("---\n")
        md.append("## âœ… ì¥ì  (Strengths)\n")
        for i, strength in enumerate(self.strengths, 1):
            md.append(f"### {i}. **{strength.get('title', '')}**")
            md.append(strength.get('description', ''))
            md.append("")

        # í•œê³„ì 
        md.append("---\n")
        md.append("## âš ï¸ í•œê³„ì  (Limitations)\n")
        for i, limitation in enumerate(self.limitations, 1):
            md.append(f"### {i}. **{limitation.get('title', '')}**")
            md.append(limitation.get('description', ''))
            md.append("")

        # í–¥í›„ ê°œì„  ë°©í–¥
        md.append("---\n")
        md.append("## ğŸš€ í–¥í›„ ê°œì„  ë°©í–¥ (Future Directions)\n")
        md.append("| ì˜ì—­ | ì œì•ˆ | ì˜ˆìƒ ê¸°ê°„ | ì ì¬ì  ì˜í–¥ |")
        md.append("|------|------|-----------|-------------|")
        for direction in self.future_directions:
            area = direction.get('area', '')
            suggestion = direction.get('suggestion', '')
            timeline = direction.get('timeline', '')
            impact = direction.get('impact', '')
            md.append(f"| **{area}** | {suggestion} | {timeline} | {impact} |")
        md.append("")

        # ì í•©ì„± í‰ê°€
        if self.relevance_scores:
            md.append("---\n")
            md.append("## ğŸ“Š ìœ ì € ì í•©ì„± í‰ê°€\n")
            md.append("| ì—°êµ¬ ë¶„ì•¼ | ì í•©ë„ | ì´ìœ  |")
            md.append("|-----------|--------|------|")
            for field_name, score_info in self.relevance_scores.items():
                stars = "â­" * score_info.get('score', 0)
                reason = score_info.get('reason', '')
                md.append(f"| **{field_name}** | {stars} | {reason} |")
            md.append("")

        # ê²°ë¡ 
        md.append("---\n")
        md.append("## ğŸ¯ ê²°ë¡ \n")
        md.append(f"*í‰ê°€ ì¼ì‹œ: {self.evaluated_at[:10]}*")
        md.append(f"*ì‚¬ìš© ëª¨ë¸: {self.model_used}*")

        return "\n".join(md)

    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        return asdict(self)


class GeminiClient:
    """Gemini API í´ë¼ì´ì–¸íŠ¸."""

    def __init__(self, api_key: str = None, model: str = DEFAULT_MODEL):
        """
        Initialize Gemini client.

        Args:
            api_key: Google AI API key
            model: Gemini model name
        """
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        self.model = model
        self.timeout = aiohttp.ClientTimeout(total=120)

    async def generate(self, prompt: str, system_instruction: str = None) -> str:
        """
        Generate content using Gemini API.

        Args:
            prompt: User prompt
            system_instruction: System instruction (optional)

        Returns:
            Generated text
        """
        url = f"{GEMINI_API_URL}/{self.model}:generateContent?key={self.api_key}"

        # Build request body
        contents = [{"parts": [{"text": prompt}]}]

        body = {"contents": contents}

        if system_instruction:
            body["systemInstruction"] = {"parts": [{"text": system_instruction}]}

        # Generation config
        body["generationConfig"] = {
            "temperature": 0.7,
            "topP": 0.95,
            "topK": 40,
            "maxOutputTokens": 8192,
        }

        async with aiohttp.ClientSession(timeout=self.timeout) as session:
            async with session.post(url, json=body) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"Gemini API error: {response.status} - {error_text}")

                data = await response.json()

                # Extract generated text
                candidates = data.get("candidates", [])
                if candidates:
                    content = candidates[0].get("content", {})
                    parts = content.get("parts", [])
                    if parts:
                        return parts[0].get("text", "")

                return ""


class PaperEvaluator:
    """ë…¼ë¬¸ í‰ê°€ ì‹œìŠ¤í…œ."""

    SYSTEM_INSTRUCTION = """ë‹¹ì‹ ì€ ë°”ì´ì˜¤ë©”ë””ì»¬ ì—°êµ¬ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ë…¼ë¬¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. ì—°êµ¬ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½
2. ì—°êµ¬ì˜ ì¥ì ì„ 5ê°€ì§€ ì´ìƒ ë¶„ì„
3. ì—°êµ¬ì˜ í•œê³„ì ì„ 5ê°€ì§€ ì´ìƒ ë¶„ì„
4. í–¥í›„ ê°œì„  ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆ
5. ë‹¤ì–‘í•œ ì—°êµ¬ ë¶„ì•¼ë³„ ì í•©ì„± í‰ê°€

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” ì˜ë¬¸ ë³‘ê¸° ê°€ëŠ¥í•©ë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ í•¨ê»˜ ë¶„ì„í•˜ë©°, ê³¼í•™ì  ì •í™•ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤."""

    EVALUATION_PROMPT_TEMPLATE = """ë‹¤ìŒ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  í‰ê°€í•´ì£¼ì„¸ìš”.

## ë…¼ë¬¸ ì •ë³´
- ì œëª©: {title}
- ì €ë„: {journal} ({year})
- ì €ì: {authors}
- DOI: {doi}
- PMID: {pmid}
- ì¸ìš© ìˆ˜: {citations}

## ì´ˆë¡
{abstract}

## ë³¸ë¬¸ (ê°€ëŠ¥í•œ ê²½ìš°)
{full_text}

---

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

```json
{{
    "research_summary": "ì—°êµ¬ ë‚´ìš© 2-3ë¬¸ì¥ ìš”ì•½",
    "key_findings": [
        "ì£¼ìš” ë°œê²¬ 1",
        "ì£¼ìš” ë°œê²¬ 2",
        "ì£¼ìš” ë°œê²¬ 3"
    ],
    "methodology": "ì‚¬ìš©ëœ ì—°êµ¬ ë°©ë²•ë¡  ì„¤ëª…",
    "strengths": [
        {{"title": "ì¥ì  ì œëª©", "description": "ì¥ì  ìƒì„¸ ì„¤ëª…"}},
        {{"title": "ì¥ì  ì œëª©", "description": "ì¥ì  ìƒì„¸ ì„¤ëª…"}}
    ],
    "limitations": [
        {{"title": "í•œê³„ì  ì œëª©", "description": "í•œê³„ì  ìƒì„¸ ì„¤ëª…"}},
        {{"title": "í•œê³„ì  ì œëª©", "description": "í•œê³„ì  ìƒì„¸ ì„¤ëª…"}}
    ],
    "future_directions": [
        {{"area": "ì—°êµ¬ ì˜ì—­", "suggestion": "ê°œì„  ì œì•ˆ", "timeline": "ì˜ˆìƒ ê¸°ê°„", "impact": "ì ì¬ì  ì˜í–¥ë„ (ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ)"}},
        {{"area": "ì—°êµ¬ ì˜ì—­", "suggestion": "ê°œì„  ì œì•ˆ", "timeline": "ì˜ˆìƒ ê¸°ê°„", "impact": "ì ì¬ì  ì˜í–¥ë„"}}
    ],
    "relevance_scores": {{
        "ì—°êµ¬ ë¶„ì•¼ëª…": {{"score": 5, "reason": "ì í•©í•œ ì´ìœ "}},
        "ë‹¤ë¥¸ ë¶„ì•¼ëª…": {{"score": 3, "reason": "ì í•©í•œ ì´ìœ "}}
    }}
}}
```

ì°¸ê³ : scoreëŠ” 1-5 ì‚¬ì´ ì •ìˆ˜ (5=ë§¤ìš° ì í•©, 1=ì í•©í•˜ì§€ ì•ŠìŒ)"""

    def __init__(self, api_key: str = None, model: str = DEFAULT_MODEL):
        """
        Initialize paper evaluator.

        Args:
            api_key: Gemini API key
            model: Gemini model name
        """
        self.gemini = GeminiClient(api_key=api_key, model=model)
        self.model = model
        self.crawler = WebCrawlerAgent()
        self.fulltext_fetcher = FullTextFetcher()

    async def fetch_paper(self, doi: str = None, pmid: str = None, url: str = None) -> Optional[FetchedPaper]:
        """
        Fetch paper information from various sources.

        Args:
            doi: DOI string
            pmid: PubMed ID
            url: Paper URL

        Returns:
            FetchedPaper object or None
        """
        paper = None

        if doi:
            paper = await self.crawler.fetch_by_doi(doi)
        elif url:
            paper = await self.crawler.fetch_by_url(url)
        elif pmid:
            papers = await self.crawler.search_pubmed(f"{pmid}[uid]", max_results=1)
            if papers:
                paper = papers[0]

        # Try to get full text
        if paper:
            try:
                full_text = await self.fulltext_fetcher.fetch(
                    pmid=paper.pmid,
                    pmcid=paper.pmcid,
                    doi=paper.doi,
                    use_playwright=False  # ì†ë„ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”
                )
                if full_text:
                    paper.full_text = full_text
            except Exception as e:
                logger.warning(f"Full text fetch failed: {e}")

        return paper

    async def search_and_get_latest(self, query: str, max_results: int = 5) -> List[FetchedPaper]:
        """
        Search PubMed and return latest papers.

        Args:
            query: Search query
            max_results: Maximum results

        Returns:
            List of papers
        """
        return await self.crawler.search_pubmed(
            query=query,
            max_results=max_results,
            sort="pub_date"
        )

    async def evaluate(self, paper: FetchedPaper) -> PaperEvaluation:
        """
        Evaluate a paper using Gemini API.

        Args:
            paper: FetchedPaper object

        Returns:
            PaperEvaluation object
        """
        # Build evaluation prompt
        prompt = self.EVALUATION_PROMPT_TEMPLATE.format(
            title=paper.title,
            journal=paper.journal,
            year=paper.year,
            authors=", ".join(paper.authors[:10]),
            doi=paper.doi or "N/A",
            pmid=paper.pmid or "N/A",
            citations=paper.citation_count,
            abstract=paper.abstract or "ì´ˆë¡ ì—†ìŒ",
            full_text=paper.full_text[:15000] if paper.full_text else "ì „ë¬¸ ì—†ìŒ (ì´ˆë¡ë§Œ ë¶„ì„)"
        )

        # Call Gemini API
        response = await self.gemini.generate(
            prompt=prompt,
            system_instruction=self.SYSTEM_INSTRUCTION
        )

        # Parse JSON response
        eval_data = self._parse_json_response(response)

        # Create evaluation object
        evaluation = PaperEvaluation(
            title=paper.title,
            authors=paper.authors,
            journal=paper.journal,
            year=paper.year,
            doi=paper.doi,
            pmid=paper.pmid,
            url=paper.url,
            citation_count=paper.citation_count,
            model_used=self.model,
            **eval_data
        )

        return evaluation

    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """Parse JSON from Gemini response."""
        # Try to extract JSON from markdown code blocks
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON object directly
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                json_str = json_match.group(0)
            else:
                logger.warning("No JSON found in response")
                return {}

        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            # Try to fix common issues
            json_str = re.sub(r',\s*}', '}', json_str)  # Remove trailing commas
            json_str = re.sub(r',\s*]', ']', json_str)
            try:
                return json.loads(json_str)
            except:
                return {}


async def main():
    parser = argparse.ArgumentParser(description="ë…¼ë¬¸ ì‹¬ì¸µ í‰ê°€ ì‹œìŠ¤í…œ")
    parser.add_argument("--doi", type=str, help="ë…¼ë¬¸ DOI")
    parser.add_argument("--pmid", type=str, help="PubMed ID")
    parser.add_argument("--url", type=str, help="ë…¼ë¬¸ URL")
    parser.add_argument("--search", type=str, help="PubMed ê²€ìƒ‰ì–´")
    parser.add_argument("--output", type=str, help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (.md ë˜ëŠ” .json)")
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL, help="Gemini ëª¨ë¸ëª…")
    parser.add_argument("--list-models", action="store_true", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")

    args = parser.parse_args()

    if args.list_models:
        print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸:")
        print("  - gemini-2.0-flash (ê¸°ë³¸, ê°€ì¥ ë¹ ë¥´ê³  ì €ë ´)")
        print("  - gemini-2.0-flash-lite (ë” ë¹ ë¥´ê³  ì €ë ´)")
        print("  - gemini-1.5-pro (ê³ í’ˆì§ˆ, ë” ë¹„ìŒˆ)")
        print("  - gemini-1.5-flash (ê· í˜•)")
        return

    if not any([args.doi, args.pmid, args.url, args.search]):
        parser.print_help()
        print("\nì˜ˆì‹œ:")
        print("  python scripts/paper_evaluator.py --doi '10.1038/s41586-025-09896-x'")
        print("  python scripts/paper_evaluator.py --pmid '41501451'")
        print("  python scripts/paper_evaluator.py --search 'mitochondrial transfer neuropathy 2026'")
        return

    print("ğŸ”¬ ë…¼ë¬¸ í‰ê°€ ì‹œìŠ¤í…œ ì‹œì‘...")
    print(f"   ëª¨ë¸: {args.model}\n")

    try:
        evaluator = PaperEvaluator(model=args.model)
    except ValueError as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        print("   GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return

    # Fetch paper
    paper = None

    if args.search:
        print(f"ğŸ” PubMed ê²€ìƒ‰ ì¤‘: '{args.search}'")
        papers = await evaluator.search_and_get_latest(args.search, max_results=5)

        if not papers:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return

        print(f"\nğŸ“š ê²€ìƒ‰ ê²°ê³¼ ({len(papers)}í¸):")
        for i, p in enumerate(papers, 1):
            print(f"  {i}. [{p.year}] {p.title[:60]}...")

        print("\n1ë²ˆ ë…¼ë¬¸ì„ í‰ê°€í•©ë‹ˆë‹¤...")
        paper = papers[0]
    else:
        print("ğŸ“¥ ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        paper = await evaluator.fetch_paper(
            doi=args.doi,
            pmid=args.pmid,
            url=args.url
        )

    if not paper:
        print("âŒ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return

    print(f"âœ“ ë…¼ë¬¸: {paper.title[:60]}...")
    print(f"  ì €ë„: {paper.journal} ({paper.year})")
    print(f"  ì¸ìš©: {paper.citation_count}")

    if paper.full_text:
        print(f"  ì „ë¬¸: {len(paper.full_text):,} ê¸€ì")
    else:
        print("  ì „ë¬¸: ì—†ìŒ (ì´ˆë¡ë§Œ ë¶„ì„)")

    # Evaluate
    print("\nğŸ¤– Gemini APIë¡œ ë¶„ì„ ì¤‘...")
    evaluation = await evaluator.evaluate(paper)

    # Output
    if args.output:
        output_path = Path(args.output)

        if output_path.suffix == '.json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(evaluation.to_dict(), f, ensure_ascii=False, indent=2)
        else:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(evaluation.to_markdown())

        print(f"\nâœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {output_path}")
    else:
        # Print to console
        print("\n" + "=" * 80)
        print(evaluation.to_markdown())

    print("\nâœ… í‰ê°€ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
